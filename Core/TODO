* Idee: [Key|Value]_Context_Type in [Read|Write]_[Key|Value]_Context_Type
  aufteilen, dazu eine New_[Read|Write]_[Key|Value]_Context Funktion, die
  Daten ueber den Knoten bekommt, zumindest den Grad. Dann koennen die
  Write-Prozeduren daraus einen Binaerbaum in einem Array (Heap) aufbauen und
  dabei "positive" und "negative" Diffs bei der Praefixkomprimierung speichern.
  Das Dekodieren muesste dann viel schneller gehen, weil in einem Knoten mit
  Grad N nicht im Schnitt N/2 Dinge dekodiert werden muessen, sondern:
  Wir brauchen einen Baum mit Hoehe H := ceil(log_2(N)) + 1 (wobei Hoehe die
  Anzahl der Knoten ist), weil wir dann ceil(log_2(N)) Ebenen haben und so
  2^{ceil(log_2(N))+1} - 1 = 2^H - 1 Eintraege speichern koennen. Wir speichern
  in der Wurzel den ganzen Eintrag und in der Folge immer nur ein Diff zum
  Vater. Erwartungswert an Dekodierungen:
           2^{-H} * \sum_{i=0}^{H-1} 2^i * i
           \sum_{i=0}^{H-1} 2^{i-H} * i
    (\h -> 1.0/(2**(h)-1) * (sum $ map (\i -> 2**i * i) [0.0 .. h-1.0])) H
  Fuer einen Knoten mit 31 Eintraegen brauchen wir, weil 2^5 - 1 = 31,
  einen Baum der Hoehe 5, also mit 4 Etagen. Fuer jeden Knoten der i-ten Etage
  brauchen wir i Dekodierungen. Da auf der i-ten Etage 2^i Eintraege sind,
  braeuchte man i * 2^i Dekodierungen insgesamt fuer die Etage, fuer den
  Erwartungswert muss man das dann noch durch 2^5 - 1 = 2^H - 1 teilen.
   8 Eintraege => 1.4 Dekodierungen
  15 Eintraege => 2.3 Dekodierungen
  31 Eintraege => 3.2 Dekodierungen
  63 Eintraege => 4.1 Dekodierungen
   1
 2   2
3 3 3 3

* Management-Schicht
  * Jede Column-Family c wird von einem regulaeren Ausdruck r beschuetzt
  * Operationen:
    * Selektion nach Rowkey (sind Bereichsanfragen der Keys)
    * Filter Existenz von Attributen
      jeweils mit eigener Funktion, die z. B. einen Regex matcht
      Anmerkung 1: Existenz von Attribut heiszt so viel wie: Wert /= NULL
      Anmerkung 2: Attributfilter schmeiszen Attribute raus
    * Inner/Left-Outer/Right-Outer/Outer-Join-on-Attribute
    * Inner/Left-Outer/Right-Outer/Outer-Join-on-Rowkey
      (den Outer-Join zweier Column-Families nennen wir auch Merge)
      Vorschlag: alle Outer-Join verbieten, da es sich sowieso um eine
                 duenn-besetzte Tabelle handelt; es wuerde zwar Sinn machen,
                 durch Inner-Join oder Left/Right-Outer-Join zu filtern, wenn
                 der Benutzer weisz, dass jeder Datensatz in einer Column Family
                 ein bestimmtes Attribut hat
    * Projektion auf Attributteilmenge A
      Anmerkung: (1) Ein Datensatz muss nicht Werte zu allen a in A haben, weil
      die Tabelle duenn-besetzt ist. (2) Ein Datensatz kann Attribute b not in A
      haben, weil der regulaere Ausdruck auf mehr Attribute matchen kann.
      Um ungewollte Attribute zu filtern, muss ein Attributfilter angewendet
      werden (siehe oben).
  * Optimizer: Query in Baumdarstellung, Blaetter ^= unten ^= erst auswerten
    Umgekehrte Reihenfolge der Operationen:
    * Attribut-Joins
    * Rowkey-Joins
    * Attributfilter
    * mergelose Selektion auf Column Families (Cursor)
    * Projektion (Auswahl der Column Families)
  * bei Projektion auf Attributmenge A koennen die benoetigten ColFams aus wie
    der Menge der ColFams C folgt ausgesucht werden:
    * f.a. c in A: S_c := { a in A : a matches r_c }  =>   S_c Teilmenge von A
    * suche Set Cover {S_c1, ..., S_cN} von A
    * dann muessen 
  * Column-Families mit Attribut-Pattern-Matching (= vert. Part.)
  * hier auch direkt Intervalle festlegen?        (= horiz. Part.)

* Schnittstelle
  * REST
  * http://server.de/datenbank/datenbank/[-infty,infty]/attribut1,attribut5/HEAD
    alle Datensaetze, nur Attribute attribut1 und attribut5, letzte Revision
  * http://server.de/datenbank/datenbank/[com.bbc,com.cnn]/*name*/<=2009-09-10
    Datensaetze von com.bbc bis com.cnn, jeweils inklusive, alle Attribute, die
    auf das Muster *name* passen, die letzte Revision vor 2009-09-10
  * http://server.de/datenbank/datenbank/(com.bbc,com.cnn]/vorname/HEAD^3
    Datenseatze von com.bbc, exklusiv, bis com.cnn, inklusiv, Attribut vorname,
    dritt-aktuellste Revision
  * erst Einfach-Rechner-Loesung, spaeter Cluster (siehe Verteilung)

* Verteilung
  * moeglichst gut bei horiz./vert. Partitionierung voraus-beruecksichtigen
  * moeglichst gut bei Map-Reduce voraus-beruecksichtigen (-> Jobs?)
  * auch ueber REST?
  * Vorschlag/Idee:
    * logisch in eine neue oberste Ebene ansiedeln
    * Anfragen ueber REST wie bei einem einzelnen Computer
    * zusaetzlich: Anfrage "auf welchen Computern liegen welche Teile einer
      Datenbank?"
  


* MapReduce auf externes Sortieren umstellen:
  * externes Mergesort
  * in-place in-memory Quicksort [oder Timsort] oder Heapsort oder so
  * Fibonacci-Heap, um beim mergen das Minimum auszuwaehlen?





* Shadowing:
  Einfaches Shadowing aus Folien nicht uebertragbar, da offensives Splitten
  nicht moeglich ist und wir einen Blink-Tree haben.
  1. Fuer alle Versionen des Trees gibt es eine gemeinsame Refcount-Map:
     Phys-Addr -> Refcount
     Die Refcount eines Knotens zeigt an, wie viele andere KNOTEN auf diesen
     Knoten zeigen.
     Fuer Knoten N sei L logische und P physische Adreses.
     Clone:
       kopiere Wurzel N mit L an neue P und setze Refcount(P) := Degree(N)
     Relocate:
       schreibe N mit L an neue P und setze Refcount(P) := Pointer_Count(N)
       wobei Pointer_Count(N) := |Pointers(N)|
       wobei Pointers(N) := Children(N) \cup { Left(N), Right(N), Parent(N) falls Valid }
     Write:
       if Refcount(P) = Pointer_Count(N):
         Simply_Write
         P \in (Pointers(N') \ Pointers(N)): Dec_Refcount(P);
         P \in (Pointers(N) \ Pointers(N')): Inc_Refcount(P);
       else
         ach alles Kacke verdammte
     Dec_Refcount:
       Refcount(N) := Refcount(N) - 1
       if Refcount(N) = 0 then Free_Node(N)
     Inc_Refcount:
       Refcount(N) := Refcount(N) + 1
  2. Fuer jede Version des Trees gibt es eine Map
     Virt-Addr -> Phys-Addr
     Koennte man so realisieren: insgesamt nur eine Map
     (Tree-Version-ID, Virt-Addr) -> Phys-Addr
     wenn dann (ID, Addr) gelookupt werden soll und nicht in der Map enthalten
     ist, wird bei Vorgaengern geschaut, bis gefunden, und dann 
     (ID, Addr) -> Phys-Addr eingefuegt
  3. Vorgaenger-Map: 
     (Tree-Version-ID) -> (Tree-Version-ID)
     wenn geshadowed wird, ist die neue Tree-Version-ID der maximale Key in
     der Map + 1
  
* Storage_Pools fuer Caches

* Die Heap-Geschichte mit 32 Bit TESTEN TESTEN TEST


ERLEDIGT:
* Transaktionen: Gen_Buffers: mit einer Write-Liste und einem kleinen Cache
  <- die Idee war ja, dass Read nicht den Buffer zumuellt. Das war auch nie
  der Fall auszer fuer die Read-Prozedur, die ein Item_Constant_Access_Type
  setzt (die muss das auch machen).
* Gen_Heaps:   auch auf OO umstellen (?) <- wenn auch unschoen gemacht 
  (if Read-Transaction then bla else blupp in Gen_Heaps.Get)
* Auf 32-Bit-Systemen gibt es ne Exception im Heap, wenn die Chunks >4GB werden,
  weil IO.Blocks.Size_Type verwendet wird.
* Is_Context_Free_Serialization
  Wahrscheinlich mit Degree >= 2 bestmoeglich gefixt
* Unset_Free_Following koennte die Transaktion unkontrolliert aufblasen!!
  Doch nicht zu Gebieten zusammenfassen?
  STIMMT DOCH NICHT, GLAUB ICH
* Gen_Heaps Cursor => Problem irgendwie beheben, eine Moeglichkeit waere
  in Gen_BTrees Transaktions-Cursor zu bauen


Alt, aber vielleicht noch interessant und auf jeden Fall noch nicht erledigt:

* Table_Tree
	* Siehe Timed_Table_Tree und streiche die Times.
* Timed_Table_Tree
	* Gen_BTree mit zwei Dimensionen Row, Column, Time
	* Iterator bekommt einen Selektor uebergeben, der anhand von Columns und
	  Times rausfiltern kann
	* Vorgefertigte Selektoren fuer Times (Time <= Now, aktuellsten 3
	  Eintraege usw.) und Columns (beginnt-mit)
* Bitmap
	* Verkettete Liste von Bloecken
	* Komprimierung: statt (0, ..., 0) oder (1, ..., 1) (n, 0) bzw. (n, 1)
	* Oder diese baumartige Bitmap
	* Iterator: von n-tem Eintrag bis m-ten Eintrag
	* Reorganize Prozedure
* Cache(s)
	* Eine besondere Realisierung von Gen_IO; der Cache bekommt ein anderes
	  Gen_IO uebergeben, das er cacht, ist aber gleichzeitig selbst ein
	  Gen_IO.

