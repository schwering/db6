Upcoming: MapReduce
However, this implementation will not live long.
The next implementation will be nearer to the real MapReduce by Google:

The Map function takes tuples from the (Key_Type_1, Value_Type_1) space and
emits zero or more tuples from a (Key_Type_2, Value_Type_2) space.

Emitted tuples are stored somewhere, probably in a BTree with keys of type
Key_Type_2 and values of type List_Of_Value_Type_2. The reason for this storage
is that this already aggregates the emitted tuples by the key of type Key_Type_2
and makes iterating the values of type Value_Type_2 associated with the key
of type Key_Type_2 easy.

Then the Reduce function takes such an object of type Key_Type_2 an iterator
(the BTree Cursor_Type or so) that represents the List_Of_Value_Type_2.

Maybe an additional Partition function assigns each (Key_Type_2,
List_Of_Value_Type_2) to a reduce process by just hashing Key_Type_2 and
taking the result modulo the reduce process count as index of the the
reduce process. Pretty easy.


Would be cool to store (Key, List_Of_Values) tuples. While this is easy with
the current BLOB_Tree and would also be easy with the heterogeneous BTree
mentionted above (Max_Size_Of_Value(List) = +\infty suffices), the problem is
how to append values (and possibly also delete something). <-- Das Problem
ist mit der neuen Heap-Operation Append behoben.



Fahrplan:

* Map-Reduce
  * erstmal nur auf einzelnen Column-Families, also B-Trees, ausfuehrbar
  * spaeter: Column-Families joinen (sehr wichtig, z. B. wegen Blob-Trees)
  * Garantie: die Attribute einer ID werden direkt nacheinander reduced

* Management-Schicht
  * Column-Families mit Attribut-Pattern-Matching (= vert. Part.)
  * hier auch direkt Intervalle festlegen?        (= horiz. Part.)

* Schnittstelle
  * REST
  * http://server.de/datenbank/datenbank/[-infty,infty]/attribut1,attribut5/HEAD
    alle Datensaetze, nur Attribute attribut1 und attribut5, letzte Revision
  * http://server.de/datenbank/datenbank/[com.bbc,com.cnn]/*name*/<=2009-09-10
    Datensaetze von com.bbc bis com.cnn, jeweils inklusive, alle Attribute, die
    auf das Muster *name* passen, die letzte Revision vor 2009-09-10
  * http://server.de/datenbank/datenbank/(com.bbc,com.cnn]/vorname/HEAD^3
    Datenseatze von com.bbc, exklusiv, bis com.cnn, inklusiv, Attribut vorname,
    dritt-aktuellste Revision
  * erst Einfach-Rechner-Loesung, spaeter Cluster (siehe Verteilung)

* Verteilung
  * moeglichst gut bei horiz./vert. Partitionierung voraus-beruecksichtigen
  * moeglichst gut bei Map-Reduce voraus-beruecksichtigen (-> Jobs?)
  * auch ueber REST?
  * Vorschlag/Idee:
    * logisch in eine neue oberste Ebene ansiedeln
    * Anfragen ueber REST wie bei einem einzelnen Computer
    * zusaetzlich: Anfrage "auf welchen Computern liegen welche Teile einer
      Datenbank?"
  





* Shadowing:
  Einfaches Shadowing aus Folien nicht uebertragbar, da offensives Splitten
  nicht moeglich ist und wir einen Blink-Tree haben.
  1. Fuer alle Versionen des Trees gibt es eine gemeinsame Refcount-Map:
     Phys-Addr -> Refcount
     Die Refcount eines Knotens zeigt an, wie viele andere KNOTEN auf diesen
     Knoten zeigen.
     Fuer Knoten N sei L logische und P physische Adreses.
     Clone:
       kopiere Wurzel N mit L an neue P und setze Refcount(P) := Degree(N)
     Relocate:
       schreibe N mit L an neue P und setze Refcount(P) := Pointer_Count(N)
       wobei Pointer_Count(N) := |Pointers(N)|
       wobei Pointers(N) := Children(N) \cup { Left(N), Right(N), Parent(N) falls Valid }
     Write:
       if Refcount(P) = Pointer_Count(N):
         Simply_Write
         P \in (Pointers(N') \ Pointers(N)): Dec_Refcount(P);
         P \in (Pointers(N) \ Pointers(N')): Inc_Refcount(P);
       else
         ach alles Kacke verdammte
     Dec_Refcount:
       Refcount(N) := Refcount(N) - 1
       if Refcount(N) = 0 then Free_Node(N)
     Inc_Refcount:
       Refcount(N) := Refcount(N) + 1
  2. Fuer jede Version des Trees gibt es eine Map
     Virt-Addr -> Phys-Addr
     Koennte man so realisieren: insgesamt nur eine Map
     (Tree-Version-ID, Virt-Addr) -> Phys-Addr
     wenn dann (ID, Addr) gelookupt werden soll und nicht in der Map enthalten
     ist, wird bei Vorgaengern geschaut, bis gefunden, und dann 
     (ID, Addr) -> Phys-Addr eingefuegt
  3. Vorgaenger-Map: 
     (Tree-Version-ID) -> (Tree-Version-ID)
     wenn geshadowed wird, ist die neue Tree-Version-ID der maximale Key in
     der Map + 1
  
* Storage_Pools fuer Caches

* Die Heap-Geschichte mit 32 Bit TESTEN TESTEN TEST

ERLEDIGT:
* Transaktionen: Gen_Buffers: mit einer Write-Liste und einem kleinen Cache
  <- die Idee war ja, dass Read nicht den Buffer zumuellt. Das war auch nie
  der Fall auszer fuer die Read-Prozedur, die ein Item_Constant_Access_Type
  setzt (die muss das auch machen).
* Gen_Heaps:   auch auf OO umstellen (?) <- wenn auch unschoen gemacht 
  (if Read-Transaction then bla else blupp in Gen_Heaps.Get)
* Auf 32-Bit-Systemen gibt es ne Exception im Heap, wenn die Chunks >4GB werden,
  weil IO.Blocks.Size_Type verwendet wird.
* Is_Context_Free_Serialization
  Wahrscheinlich mit Degree >= 2 bestmoeglich gefixt
* Unset_Free_Following koennte die Transaktion unkontrolliert aufblasen!!
  Doch nicht zu Gebieten zusammenfassen?
  STIMMT DOCH NICHT, GLAUB ICH
* Gen_Heaps Cursor => Problem irgendwie beheben, eine Moeglichkeit waere
  in Gen_BTrees Transaktions-Cursor zu bauen


Alt, aber vielleicht noch interessant und auf jeden Fall noch nicht erledigt:

* Table_Tree
	* Siehe Timed_Table_Tree und streiche die Times.
* Timed_Table_Tree
	* Gen_BTree mit zwei Dimensionen Row, Column, Time
	* Iterator bekommt einen Selektor uebergeben, der anhand von Columns und
	  Times rausfiltern kann
	* Vorgefertigte Selektoren fuer Times (Time <= Now, aktuellsten 3
	  Eintraege usw.) und Columns (beginnt-mit)
* Bitmap
	* Verkettete Liste von Bloecken
	* Komprimierung: statt (0, ..., 0) oder (1, ..., 1) (n, 0) bzw. (n, 1)
	* Oder diese baumartige Bitmap
	* Iterator: von n-tem Eintrag bis m-ten Eintrag
	* Reorganize Prozedure
* Cache(s)
	* Eine besondere Realisierung von Gen_IO; der Cache bekommt ein anderes
	  Gen_IO uebergeben, das er cacht, ist aber gleichzeitig selbst ein
	  Gen_IO.

