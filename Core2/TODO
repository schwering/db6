* Gen_BTrees
      * Referenz-Werte / HTTP GET:
        Werte, deren Typ Key_Type ist. In der REST-Schnittstelle kann dann
        bei einer Punktsuche (oder auch beim Cursor?) die Referenz ueber ein
        Maps.Search verfolgt werden. Die Rekursionstiefe kann per GET-Parameter
        angegeben werden.
        REST GET muss dahin umgestellt werden, dass ein Cache URL -> Fetcher
        besteht, wobei URL die um Laenge und Offset bereinigte URL ist und
        Fetcher ein Objekt (Task?) ist, das einen Cursor besitzt und das man
        per Schnittstelle um das naechste Objekt (entweder direkt aus dem
        Cursor oder wie jetzt aus der Queue) bitten kann.
      * Cursor Delete verbessern:
        (Vielleicht reicht das aktuelle Delete_Range aber auch einfach aus.)
        Elemente koennen zum Loeschen vorgemerkt werden. Das eigentlich
        Loeschen findet erst statt, wenn der aktuelle Knoten verlassen
        wird. Dann wird ein Gen_Modify aufgerufen, das zum aktuellen
        Knoten laeuft (durch Exit_Cond gesteuert) und dann alle in dem
        gelesenen Knoten vorhandenen und zum Loeschen vorgemerkten
        Elemente loescht. Die Elemente, die nicht im Knoten gefunden
        werden, sind entweder schon geloescht worden oder durch ein Split
        in einen rechten Nachbarn gewandert. Diejenigen, die kleiner als
        der High-Key des betrachteten Knoten sind, koennen geloescht werden,
        die anderen werden aufgehoben und aus dem naechsten Knoten
        geloescht. Die Frage ist, ob Cursor.Node auch durch den neu
        gelesenen Knoten ersetzt wird. Die Nachbar-Adresse von Cursor.Node
        stimmt naemlich im Falle eines Splits nicht mehr, andererseits
        werden bei einem Split dann Elemente doppelt betrachtet.
      * Reorganize implementieren:
        Ein Task, der immer wieder ueber den B-Baum laeuft,
        unterlaufene Blaetter merget, hintere Bloecke in vordere
        freigewordene Bloecke kopiert und dabei heftig lockt.
        Das ganze koennte Deadlocks verhindern, indem es anfangs
        alle fuer eine Verschiebeoperation notwendigen Bloecke
        lockt, dies nach einem Timeout aber abbricht, bei Erfolg
        aber nochmal auf Konsistenz prueft; im Nicht-Erfolgsfall
        wuerde das ganze einfach neustarten.
      * Overflow-Pages:
        Wenn ein Wert (oder auch der Schluessel?) zu grosz ist,
        soll er in weitere Seiten ueberlaufen. Das wuerde aber
        viele Aenderungen in den formalen generischen Parametern
        nach sich ziehen (man braeuchte Iteratoren-aehnliche
        Dinger zum Serialisieren). Auszerdem wuerde es das Problem,
        dass grosze Datenmengen bei mehreren Eintraegen in B-Baeumen
        nicht mehrfach gespeichert werden, nicht beheben.

* Distributed_IO:
        assemble/disassemble baut Adressen
        oip = own IP address
        ctr = counter that increments with each network operation
        Write (in addr, in block): Alle muessen bestaetigen
                S := disassemble(addr)
            (*) for all (ip, addr) in S:
                -> Send ip (oip, ctr,  addr, block)
                for all:
                <- Recv (ip, ctr, addr)
                S := S \ {(ip, addr)}
                delay
                if |S| > 0 then go to (*)
        Write_New (out addr, in block):
                addr := assemble(S)
        Read (in addr, out block): Einer muss antworten
                S := disassemble(addr)
                for all (ip, addr) in S:
                -> Send ip (oip, ctr, addr, block)
                <- Recv (ip, ctr, block)


